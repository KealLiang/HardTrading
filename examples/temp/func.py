# !/usr/bin/env python
"""
Date: 2025/3/10 18:00
Desc: é€šç”¨å¸®åŠ©å‡½æ•°
"""

import hashlib
import math
import os
import pickle
import tempfile
from typing import List, Dict

import pandas as pd
import requests

from akshare.utils.tqdm import get_tqdm


def fetch_paginated_data(url: str, base_params: Dict, timeout: int = 30, cache_pages: int = 5):
    """
    ä¸œæ–¹è´¢å¯Œ-åˆ†é¡µè·å–æ•°æ®å¹¶åˆå¹¶ç»“æœï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰
    :param url: æ¥å£URL
    :type url: str
    :param base_params: åŸºç¡€è¯·æ±‚å‚æ•°
    :type base_params: dict
    :param timeout: è¯·æ±‚è¶…æ—¶æ—¶é—´
    :type timeout: int
    :param cache_pages: æ¯Né¡µä¿å­˜ä¸€æ¬¡ç¼“å­˜ï¼Œ0è¡¨ç¤ºä¸å¯ç”¨ç¼“å­˜
    :type cache_pages: int
    :return: åˆå¹¶åçš„æ•°æ®
    :rtype: pandas.DataFrame
    """
    # ç¦ç”¨ä»£ç†ï¼Œé¿å…VPNå¹²æ‰°
    proxies = {"http": None, "https": None}
    headers = {
        # ç²˜è´´è‡ªå·±çš„headers
        'Accept': '*/*',
        'Accept-Encoding': 'gzip, deflate, br, zstd',
        'Accept-Language': 'zh-CN,zh;q=0.9,en-US;q=0.8,en;q=0.7,zh-TW;q=0.6',
    }
    
    # ç”Ÿæˆç¼“å­˜æ–‡ä»¶è·¯å¾„ï¼ˆä½¿ç”¨ç³»ç»Ÿä¸´æ—¶ç›®å½•ï¼‰
    cache_file = None
    if cache_pages > 0:
        cache_key = f"{url}_{str(sorted(base_params.items()))}"
        cache_hash = hashlib.md5(cache_key.encode()).hexdigest()[:16]
        cache_file = os.path.join(tempfile.gettempdir(), f"em_cache_{cache_hash}.pkl")
    
    # å°è¯•åŠ è½½ç¼“å­˜
    temp_list, start_page, total_page = [], 1, None
    if cache_file and os.path.exists(cache_file):
        try:
            with open(cache_file, 'rb') as f:
                cache_data = pickle.load(f)
                temp_list, start_page, total_page = cache_data['data'], cache_data['page'] + 1, cache_data['total']
                print(f"ğŸ“¦ ä»ç¬¬{start_page}é¡µç»§ç»­ï¼ˆå…±{total_page}é¡µï¼‰")
        except:
            temp_list, start_page, total_page = [], 1, None
    
    # è·å–ç¬¬ä¸€é¡µï¼ˆå¦‚æœéœ€è¦ï¼‰
    params = base_params.copy()
    if start_page == 1:
        params["pn"] = 1
        r = requests.get(url, params=params, headers=headers, proxies=proxies, timeout=timeout)
        data_json = r.json()
        per_page_num = len(data_json["data"]["diff"])
        total_page = math.ceil(data_json["data"]["total"] / per_page_num)
        temp_list.append(pd.DataFrame(data_json["data"]["diff"]))
        print(f"ğŸ“Š å…±{total_page}é¡µï¼Œæ¯é¡µ{per_page_num}æ¡")
        start_page = 2
        if cache_file:
            with open(cache_file, 'wb') as f:
                pickle.dump({'data': temp_list, 'page': 1, 'total': total_page}, f)
    
    # è·å–å‰©ä½™é¡µé¢
    tqdm = get_tqdm()
    try:
        for page in tqdm(range(start_page, total_page + 1), leave=False, initial=start_page-1, total=total_page):
            params = base_params.copy()
            params["pn"] = page
            r = requests.get(url, params=params, headers=headers, proxies=proxies, timeout=timeout)
            data_json = r.json()
            temp_list.append(pd.DataFrame(data_json["data"]["diff"]))
            
            # å®šæœŸä¿å­˜ç¼“å­˜
            if cache_file and page % cache_pages == 0:
                with open(cache_file, 'wb') as f:
                    pickle.dump({'data': temp_list, 'page': page, 'total': total_page}, f)
                print(f"ğŸ’¾ å·²ç¼“å­˜è‡³ç¬¬{page}é¡µ")
        
        # æˆåŠŸå®Œæˆï¼Œåˆ é™¤ç¼“å­˜
        if cache_file and os.path.exists(cache_file):
            os.remove(cache_file)
            print(f"âœ… å®Œæˆï¼Œå·²æ¸…ç†ç¼“å­˜")
    except Exception as e:
        # å¤±è´¥æ—¶ä¿å­˜ç¼“å­˜
        if cache_file and temp_list:
            with open(cache_file, 'wb') as f:
                pickle.dump({'data': temp_list, 'page': len(temp_list), 'total': total_page}, f)
            print(f"âŒ ä¸­æ–­äºç¬¬{len(temp_list)}é¡µï¼Œç¼“å­˜å·²ä¿å­˜")
        raise e
    
    # åˆå¹¶æ•°æ®
    temp_df = pd.concat(temp_list, ignore_index=True)
    temp_df["f3"] = pd.to_numeric(temp_df["f3"], errors="coerce")
    temp_df.sort_values(by=["f3"], ascending=False, inplace=True, ignore_index=True)
    temp_df.reset_index(inplace=True)
    temp_df["index"] = temp_df["index"].astype(int) + 1
    return temp_df


def set_df_columns(df: pd.DataFrame, cols: List[str]) -> pd.DataFrame:
    """
    è®¾ç½® pandas.DataFrame ä¸ºç©ºçš„æƒ…å†µ
    :param df: éœ€è¦è®¾ç½®å‘½åçš„æ•°æ®æ¡†
    :type df: pandas.DataFrame
    :param cols: å­—æ®µçš„åˆ—è¡¨
    :type cols: list
    :return: é‡æ–°è®¾ç½®åçš„æ•°æ®
    :rtype: pandas.DataFrame
    """
    if df.shape == (0, 0):
        return pd.DataFrame(data=[], columns=cols)
    else:
        df.columns = cols
        return df
