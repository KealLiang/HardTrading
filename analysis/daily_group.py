import pandas as pd
import matplotlib.pyplot as plt
from collections import Counter

def analyze_zt_reasons(excel_file='./excel/fupan_stocks.xlsx', date=None, top_n=20, output_format='normal', plot=False):
    """
    åˆ†ææ¶¨åœåŸå› ç±»åˆ«ï¼Œå¯¹æ•°æ®è¿›è¡Œèšåˆç»Ÿè®¡
    
    å‚æ•°:
    excel_file: Excelæ–‡ä»¶è·¯å¾„
    date: æŒ‡å®šæ—¥æœŸï¼Œæ ¼å¼ä¸º "YYYYå¹´MMæœˆDDæ—¥"ï¼Œä¸ºNoneæ—¶åˆ†ææ‰€æœ‰æ—¥æœŸæ•°æ®
    top_n: æ˜¾ç¤ºå‰å¤šå°‘ä¸ªæœ€å¸¸è§çš„åŸå› ç±»åˆ«
    output_format: è¾“å‡ºæ ¼å¼ï¼Œå¯é€‰ 'normal'(é»˜è®¤), 'simple'(ç®€æ´), 'detailed'(è¯¦ç»†)
    plot: æ˜¯å¦ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨
    
    è¿”å›:
    æ— ï¼Œç›´æ¥æ‰“å°åˆ†æç»“æœ
    """
    plt.rcParams['font.sans-serif'] = ['SimHei']  # 'SimHei'
    plt.rcParams['axes.unicode_minus'] = False  # æ­£ç¡®æ˜¾ç¤ºè´Ÿå·

    # è¯»å–è¿æ¿æ•°æ®å’Œé¦–æ¿æ•°æ®
    lianban_data = pd.read_excel(excel_file, sheet_name="è¿æ¿æ•°æ®", index_col=0)
    shouban_data = pd.read_excel(excel_file, sheet_name="é¦–æ¿æ•°æ®", index_col=0)
    
    # é€‰æ‹©è¦åˆ†æçš„æ—¥æœŸåˆ—
    if date:
        if date in lianban_data.columns:
            lianban_dates = [date]
        else:
            print(f"é”™è¯¯: æœªæ‰¾åˆ°æ—¥æœŸ {date}")
            return
    else:
        lianban_dates = lianban_data.columns
    
    # ç»Ÿè®¡æ‰€æœ‰ç±»åˆ«
    all_reasons = Counter()
    daily_results = []
    
    # å¤„ç†è¿æ¿æ•°æ®
    for date in lianban_dates:
        # æå–å½“æ—¥è¿æ¿æ•°æ®
        lianban_col = lianban_data[date].dropna()
        lianban_stocks = lianban_col.str.split(';').apply(lambda x: [item.strip() for item in x])
        
        lianban_df = pd.DataFrame(lianban_stocks.tolist(), columns=[
            'è‚¡ç¥¨ä»£ç ', 'è‚¡ç¥¨ç®€ç§°', 'æ¶¨åœå¼€æ¿æ¬¡æ•°', 'æœ€ç»ˆæ¶¨åœæ—¶é—´',
            'å‡ å¤©å‡ æ¿', 'æœ€æ–°ä»·', 'é¦–æ¬¡æ¶¨åœæ—¶é—´', 'æœ€æ–°æ¶¨è·Œå¹…',
            'è¿ç»­æ¶¨åœå¤©æ•°', 'æ¶¨åœåŸå› ç±»åˆ«'
        ])
        
        # æå–å½“æ—¥é¦–æ¿æ•°æ®
        shouban_col = shouban_data[date].dropna()
        shouban_stocks = shouban_col.str.split(';').apply(lambda x: [item.strip() for item in x])
        
        # é¦–æ¿æ•°æ®å¯èƒ½æœ‰ä¸åŒçš„åˆ—ç»“æ„ï¼Œè¿™é‡Œå‡è®¾æœ€åä¸€åˆ—æ˜¯æ¶¨åœåŸå› ç±»åˆ«
        shouban_df = pd.DataFrame(shouban_stocks.tolist())
        shouban_reasons_col = shouban_df.iloc[:, -1] if not shouban_df.empty else pd.Series([])
        
        # åˆ†æè¿æ¿æ•°æ®ä¸­çš„æ¶¨åœåŸå› 
        lianban_reasons = Counter()
        for reason_str in lianban_df['æ¶¨åœåŸå› ç±»åˆ«']:
            if pd.notna(reason_str):
                # æ‹†åˆ†"+"è¿æ¥çš„åŸå› 
                reasons = [r.strip() for r in reason_str.split('+')]
                for r in reasons:
                    if r:  # ç¡®ä¿ä¸æ˜¯ç©ºå­—ç¬¦ä¸²
                        lianban_reasons[r] += 1
                        all_reasons[r] += 1
        
        # åˆ†æé¦–æ¿æ•°æ®ä¸­çš„æ¶¨åœåŸå› 
        shouban_reasons = Counter()
        for reason_str in shouban_reasons_col:
            if pd.notna(reason_str):
                # æ‹†åˆ†"+"è¿æ¥çš„åŸå› 
                reasons = [r.strip() for r in reason_str.split('+')]
                for r in reasons:
                    if r:  # ç¡®ä¿ä¸æ˜¯ç©ºå­—ç¬¦ä¸²
                        shouban_reasons[r] += 1
                        all_reasons[r] += 1
        
        # åˆå¹¶ä¸¤ç§æ•°æ®çš„ç»Ÿè®¡ç»“æœ
        day_reasons = lianban_reasons + shouban_reasons
        
        # å­˜å‚¨å½“æ—¥ç»“æœ
        daily_results.append({
            'date': date,
            'total_stocks': len(lianban_df) + len(shouban_df),
            'lianban_count': len(lianban_df),
            'shouban_count': len(shouban_df),
            'reasons': day_reasons,
            'lianban_df': lianban_df,
            'shouban_df': shouban_df
        })
    
    # æ ¹æ®è¾“å‡ºæ ¼å¼æ‰“å°ç»“æœ
    if output_format == 'simple':
        # ç®€æ´è¾“å‡ºæ¨¡å¼ - åªæ˜¾ç¤ºæœ€è¿‘ä¸€å¤©æˆ–æŒ‡å®šæ—¥æœŸçš„çƒ­ç‚¹
        if daily_results:
            latest_day = daily_results[-1]
            print(f"\nğŸ“… {latest_day['date']} æ¶¨åœçƒ­ç‚¹ (Top {top_n}):")
            for reason, count in latest_day['reasons'].most_common(top_n):
                print(f"{reason}: {count}æ¬¡")
            
            # æ‰“å°æ±‡æ€»ä¿¡æ¯
            print(f"\nğŸ“Š å½“æ—¥æ¶¨åœ: {latest_day['total_stocks']}åª (è¿æ¿: {latest_day['lianban_count']}, é¦–æ¿: {latest_day['shouban_count']})")
    
    elif output_format == 'detailed':
        # è¯¦ç»†è¾“å‡ºæ¨¡å¼ - æ˜¾ç¤ºæ‰€æœ‰æ—¥æœŸæ•°æ®
        for day_data in daily_results:
            print(f"\n=== {day_data['date']} æ¶¨åœåŸå› ç±»åˆ«ç»Ÿè®¡ ===")
            print(f">>> å½“æ—¥æ¶¨åœè‚¡ç¥¨æ€»æ•°: {day_data['total_stocks']}")
            print(f">>> è¿æ¿è‚¡ç¥¨æ•°: {day_data['lianban_count']}, é¦–æ¿è‚¡ç¥¨æ•°: {day_data['shouban_count']}")
            print("\n>>> æ¶¨åœåŸå› ç±»åˆ«ç»Ÿè®¡ (æŒ‰é¢‘ç‡é™åº):")
            
            for reason, count in day_data['reasons'].most_common():
                print(f"{reason}: {count}æ¬¡")
        
        # æ‰“å°æ‰€æœ‰æ—¥æœŸç»Ÿè®¡ç»“æœï¼ˆå¦‚æœåˆ†æäº†å¤šä¸ªæ—¥æœŸï¼‰
        if len(daily_results) > 1:
            print("\n=== æ‰€æœ‰æ—¥æœŸæ¶¨åœåŸå› ç±»åˆ«æ±‡æ€» ===")
            print(f">>> æ¶¨åœåŸå› ç±»åˆ«æ€»æ•°: {len(all_reasons)}")
            print("\n>>> æ¶¨åœåŸå› ç±»åˆ«ç»Ÿè®¡ (Top {top_n}):")
            
            for reason, count in all_reasons.most_common(top_n):
                print(f"{reason}: {count}æ¬¡")
    
    else:  # é»˜è®¤ normal æ¨¡å¼
        # æ ‡å‡†è¾“å‡ºæ¨¡å¼ - æ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
        for day_data in daily_results:
            print(f"\n=== {day_data['date']} æ¶¨åœçƒ­ç‚¹ ===")
            print(f"ğŸ“Š æ¶¨åœ: {day_data['total_stocks']}åª (è¿æ¿: {day_data['lianban_count']}, é¦–æ¿: {day_data['shouban_count']})")
            print("\nğŸ“ˆ çƒ­ç‚¹ç±»åˆ« (Top {}):\n".format(top_n))
            
            for i, (reason, count) in enumerate(day_data['reasons'].most_common(top_n), 1):
                print(f"{i}. {reason}: {count}æ¬¡")
        
        # æ‰“å°æ‰€æœ‰æ—¥æœŸç»Ÿè®¡ç»“æœï¼ˆå¦‚æœåˆ†æäº†å¤šä¸ªæ—¥æœŸï¼‰
        if len(daily_results) > 1:
            print("\n=== æ‰€æœ‰æ—¥æœŸæ¶¨åœåŸå› ç±»åˆ«æ±‡æ€» (Top {}) ===".format(top_n))
            
            for i, (reason, count) in enumerate(all_reasons.most_common(top_n), 1):
                print(f"{i}. {reason}: {count}æ¬¡")
    
    # å¦‚æœéœ€è¦ç»˜å›¾
    if plot and daily_results:
        # è·å–æœ€æ–°ä¸€å¤©çš„æ•°æ®è¿›è¡Œå¯è§†åŒ–
        latest_day = daily_results[-1]
        plot_reason_distribution(latest_day['date'], latest_day['reasons'], top_n)
        
    # è¿”å›åˆ†æç»“æœï¼Œä¾¿äºå…¶ä»–å‡½æ•°ä½¿ç”¨
    return daily_results


def plot_reason_distribution(date, reasons_counter, top_n=15):
    """
    ç»˜åˆ¶æ¶¨åœåŸå› åˆ†å¸ƒå›¾
    
    å‚æ•°:
    date: æ—¥æœŸå­—ç¬¦ä¸²
    reasons_counter: Counterå¯¹è±¡ï¼ŒåŒ…å«åŸå› å’Œé¢‘æ¬¡
    top_n: æ˜¾ç¤ºå‰å¤šå°‘ä¸ªæœ€å¸¸è§çš„åŸå› 
    """
    # è·å–å‰Nä¸ªæœ€å¸¸è§çš„åŸå› 
    top_reasons = reasons_counter.most_common(top_n)
    
    # æå–åŸå› å’Œé¢‘æ¬¡
    reasons = [reason for reason, _ in top_reasons]
    counts = [count for _, count in top_reasons]
    
    # åˆ›å»ºæ°´å¹³æ¡å½¢å›¾
    plt.figure(figsize=(12, 8))
    
    # ç»˜åˆ¶æ°´å¹³æ¡å½¢å›¾
    bars = plt.barh(range(len(reasons)), counts, align='center', color='cornflowerblue')
    
    # è®¾ç½®yè½´æ ‡ç­¾
    plt.yticks(range(len(reasons)), reasons)
    
    # æ·»åŠ æ•°æ®æ ‡ç­¾
    for bar in bars:
        width = bar.get_width()
        plt.text(width + 0.3, bar.get_y() + bar.get_height()/2, 
                 f'{width:.0f}', ha='left', va='center')
    
    # è®¾ç½®æ ‡é¢˜å’Œæ ‡ç­¾
    plt.title(f'{date} æ¶¨åœåŸå› ç±»åˆ«åˆ†å¸ƒ (Top {top_n})', fontsize=14)
    plt.xlabel('å‡ºç°é¢‘æ¬¡', fontsize=12)
    plt.ylabel('æ¶¨åœåŸå› ', fontsize=12)
    plt.tight_layout()
    
    # æ˜¾ç¤ºå›¾è¡¨
    plt.show()
    # å¯ä»¥é€‰æ‹©ä¿å­˜å›¾è¡¨
    # plt.savefig(f"zt_reasons_{date.replace('å¹´', '').replace('æœˆ', '').replace('æ—¥', '')}.png", dpi=300, bbox_inches='tight')


def get_latest_date_data(excel_file):
    """
    è·å–Excelæ–‡ä»¶ä¸­æœ€æ–°çš„æ—¥æœŸ
    
    å‚æ•°:
    excel_file: Excelæ–‡ä»¶è·¯å¾„
    
    è¿”å›:
    æœ€æ–°çš„æ—¥æœŸå­—ç¬¦ä¸²
    """
    try:
        lianban_data = pd.read_excel(excel_file, sheet_name="è¿æ¿æ•°æ®", index_col=0)
        latest_date = lianban_data.columns[-1]
        return latest_date
    except Exception as e:
        print(f"è·å–æœ€æ–°æ—¥æœŸæ—¶å‡ºé”™: {e}")
        return None


def find_stocks_by_hot_themes(excel_file='./excel/fupan_stocks.xlsx', date=None, top_n=5):
    """
    æ ¹æ®çƒ­ç‚¹ç±»åˆ«æ‰¾å‡ºè¦†ç›–å¤šä¸ªçƒ­ç‚¹çš„è‚¡ç¥¨
    
    å‚æ•°:
    excel_file: Excelæ–‡ä»¶è·¯å¾„
    date: æŒ‡å®šæ—¥æœŸï¼Œæ ¼å¼ä¸º "YYYYå¹´MMæœˆDDæ—¥"ï¼ŒNoneæ—¶ä½¿ç”¨æœ€æ–°æ—¥æœŸ
    top_n: è·å–æ’åå‰å‡ çš„çƒ­ç‚¹ç±»åˆ«
    
    è¿”å›:
    æ— ï¼Œç›´æ¥æ‰“å°ç»“æœ
    """
    # å¦‚æœæ²¡æœ‰æŒ‡å®šæ—¥æœŸï¼Œè·å–æœ€æ–°æ—¥æœŸ
    if date is None:
        date = get_latest_date_data(excel_file)
        if date is None:
            print("æ— æ³•è·å–æœ‰æ•ˆæ—¥æœŸ")
            return
    
    # åˆ†ææ¶¨åœæ•°æ®
    daily_results = analyze_zt_reasons(excel_file, date, top_n=top_n, output_format='simple', plot=False)
    
    if not daily_results:
        print("æœªè·å–åˆ°æœ‰æ•ˆæ•°æ®")
        return
    
    # è·å–å½“æ—¥æ•°æ®
    day_data = daily_results[0]  # å› ä¸ºæˆ‘ä»¬ä¼ å…¥çš„æ˜¯å•ä¸€æ—¥æœŸï¼Œæ‰€ä»¥åªæœ‰ä¸€ä¸ªç»“æœ
    
    # è·å–å‰Nä¸ªçƒ­ç‚¹ç±»åˆ«ï¼ˆåŒ…æ‹¬å¹¶åˆ—ï¼‰
    hot_reasons = day_data['reasons'].most_common()
    
    # æ‰¾å‡ºé¢‘æ¬¡æ’åå‰Nçš„çƒ­ç‚¹ï¼ˆåŒ…æ‹¬å¹¶åˆ—ï¼‰
    if not hot_reasons:
        print("æœªæ‰¾åˆ°çƒ­ç‚¹ç±»åˆ«")
        return
    
    # è·å–ç¬¬Nä¸ªçƒ­ç‚¹çš„é¢‘æ¬¡
    nth_count = hot_reasons[min(top_n-1, len(hot_reasons)-1)][1]
    
    # æ‰¾å‡ºæ‰€æœ‰é¢‘æ¬¡â‰¥ç¬¬Nä¸ªçƒ­ç‚¹é¢‘æ¬¡çš„çƒ­ç‚¹ï¼ˆå³åŒ…æ‹¬å¹¶åˆ—çš„æƒ…å†µï¼‰
    top_hot_reasons = [(reason, count) for reason, count in hot_reasons if count >= nth_count]
    
    print(f"\nğŸ”¥ {date} çƒ­ç‚¹ç±»åˆ« Top {len(top_hot_reasons)}:")
    for i, (reason, count) in enumerate(top_hot_reasons, 1):
        print(f"{i}. {reason}: {count}æ¬¡")
    
    # è·å–è¿æ¿å’Œé¦–æ¿æ•°æ®
    lianban_df = day_data['lianban_df']
    shouban_df = day_data['shouban_df']
    
    # åˆå¹¶ä¸¤ä¸ªDataFrame
    if shouban_df.empty:
        all_stocks_df = lianban_df.copy()
    else:
        # ç¡®ä¿é¦–æ¿DataFrameçš„åˆ—ä¸è¿æ¿DataFrameåŒ¹é…
        # å‡è®¾é¦–æ¿æ•°æ®çš„é¡ºåºä¸è¿æ¿æ•°æ®ç›¸åŒï¼Œä½†å¯èƒ½ç¼ºå°‘æŸäº›åˆ—
        shouban_df_adjusted = pd.DataFrame()
        
        # å¤åˆ¶è¿æ¿æ•°æ®çš„åˆ—ç»“æ„
        for col in lianban_df.columns:
            if col in shouban_df.columns:
                shouban_df_adjusted[col] = shouban_df[col]
            else:
                # å¦‚æœé¦–æ¿æ•°æ®ç¼ºå°‘æŸåˆ—ï¼Œç”¨ç©ºå€¼å¡«å……
                shouban_df_adjusted[col] = pd.NA
        
        # åˆå¹¶æ•°æ®
        all_stocks_df = pd.concat([lianban_df, shouban_df_adjusted], ignore_index=True)
    
    # è®¡ç®—æ¯åªè‚¡ç¥¨çš„çƒ­ç‚¹è¦†ç›–å¾—åˆ†
    stock_scores = []
    
    for _, stock_row in all_stocks_df.iterrows():
        # æå–è‚¡ç¥¨ä¿¡æ¯
        stock_code = stock_row['è‚¡ç¥¨ä»£ç ']
        stock_name = stock_row['è‚¡ç¥¨ç®€ç§°']
        stock_board = stock_row['å‡ å¤©å‡ æ¿'] if pd.notna(stock_row['å‡ å¤©å‡ æ¿']) else ''
        stock_reasons_str = stock_row['æ¶¨åœåŸå› ç±»åˆ«'] if pd.notna(stock_row['æ¶¨åœåŸå› ç±»åˆ«']) else ''
        
        # æ‹†åˆ†è‚¡ç¥¨çš„æ¶¨åœåŸå› 
        stock_reasons = [r.strip() for r in stock_reasons_str.split('+')] if stock_reasons_str else []
        
        # è®¡ç®—å¾—åˆ†ï¼šè¦†ç›–çš„çƒ­ç‚¹è¶Šé å‰ï¼Œåˆ†å€¼è¶Šé«˜
        score = 0
        covered_hot_reasons = []
        
        for hot_reason_idx, (hot_reason, _) in enumerate(top_hot_reasons):
            weight = len(top_hot_reasons) - hot_reason_idx  # æ’åé å‰çš„çƒ­ç‚¹æƒé‡æ›´é«˜
            
            if any(hot_reason in r for r in stock_reasons):
                score += weight
                covered_hot_reasons.append(hot_reason)
        
        # è®°å½•è‚¡ç¥¨å¾—åˆ†å’Œè¦†ç›–çš„çƒ­ç‚¹
        if score > 0:  # åªå…³æ³¨æœ‰è¦†ç›–çƒ­ç‚¹çš„è‚¡ç¥¨
            stock_scores.append({
                'è‚¡ç¥¨ä»£ç ': stock_code,
                'è‚¡ç¥¨ç®€ç§°': stock_name,
                'å‡ å¤©å‡ æ¿': stock_board,
                'æ¶¨åœåŸå› ç±»åˆ«': stock_reasons_str,
                'è¦†ç›–çƒ­ç‚¹': covered_hot_reasons,
                'çƒ­ç‚¹æ•°é‡': len(covered_hot_reasons),
                'å¾—åˆ†': score
            })
    
    # æ ¹æ®å¾—åˆ†å¯¹è‚¡ç¥¨æ’åº
    stock_scores.sort(key=lambda x: (x['å¾—åˆ†'], x['çƒ­ç‚¹æ•°é‡']), reverse=True)
    
    # è¾“å‡ºç»“æœ
    print("\nğŸ† è¦†ç›–çƒ­ç‚¹æœ€å¤šçš„è‚¡ç¥¨:")
    for i, stock in enumerate(stock_scores[:15], 1):  # åªæ˜¾ç¤ºå‰15åª
        covered_hot_str = ', '.join(stock['è¦†ç›–çƒ­ç‚¹'])
        print(f"{i}. {stock['è‚¡ç¥¨ä»£ç ']} {stock['è‚¡ç¥¨ç®€ç§°']} | {stock['å‡ å¤©å‡ æ¿']} | è¦†ç›–çƒ­ç‚¹: {covered_hot_str}")
        print(f"   åŸå§‹æ¶¨åœåŸå› : {stock['æ¶¨åœåŸå› ç±»åˆ«']}")
        print()
    
    return stock_scores


if __name__ == '__main__':
    # æ–‡ä»¶è·¯å¾„
    excel_file = "E:/demo/MachineLearning/HardTrading/excel/fupan_stocks.xlsx"
    
    # è·å–æœ€æ–°æ—¥æœŸ
    latest_date = get_latest_date_data(excel_file)
    
    # æ‰¾å‡ºè¦†ç›–çƒ­ç‚¹æœ€å¤šçš„è‚¡ç¥¨
    find_stocks_by_hot_themes(excel_file, date="2025å¹´04æœˆ25æ—¥", top_n=5)
    
    # å…¶ä»–ä½¿ç”¨ç¤ºä¾‹:
    # åˆ†ææœ€æ–°ä¸€å¤©çš„æ•°æ®ï¼Œä½¿ç”¨ç®€æ´æ¨¡å¼ï¼Œæ˜¾ç¤ºå‰15ä¸ªçƒ­ç‚¹
    # analyze_zt_reasons(excel_file, latest_date, top_n=15, output_format='simple', plot=True)
    
    # 2. åˆ†ææŒ‡å®šæ—¥æœŸæ•°æ®ï¼Œä½¿ç”¨æ ‡å‡†æ¨¡å¼ï¼Œå¹¶ç”Ÿæˆå›¾è¡¨
    # analyze_zt_reasons(excel_file, date="2025å¹´04æœˆ25æ—¥", output_format='normal', plot=True)
    
    # 3. åˆ†ææ‰€æœ‰æ—¥æœŸæ•°æ®ï¼Œä½¿ç”¨æ ‡å‡†æ¨¡å¼ï¼Œæ˜¾ç¤ºå‰10ä¸ªçƒ­ç‚¹
    # analyze_zt_reasons(excel_file, date=None, top_n=10)
