"""
ladder_chart_helpers.py
æ¶¨åœæ¢¯é˜Ÿå›¾è®¡ç®—è¾…åŠ©å‡½æ•°æ¨¡å—

åŒ…å«ä»¥ä¸‹åŠŸèƒ½ï¼š
- è‚¡ç¥¨æ•°æ®è·å–å’Œç¼“å­˜
- æˆäº¤é‡æ¯”è®¡ç®—
- æ–°é«˜æ ‡è®°è®¡ç®—
- å‡çº¿æ–œç‡è®¡ç®—
- è·Ÿè¸ªåˆ¤æ–­é€»è¾‘
- ç‚¸æ¿æ ¼å¼ç¼“å­˜
"""

from datetime import datetime
from functools import lru_cache

import pandas as pd

from utils.date_util import count_trading_days_between, get_n_trading_days_before
from utils.file_util import read_stock_data

# ==================== æˆäº¤é‡åˆ†æç›¸å…³å‚æ•° ====================
# è®¡ç®—æˆäº¤é‡æ¯”çš„å¤©æ•°ï¼Œå½“å¤©æˆäº¤é‡ä¸å‰Xå¤©å¹³å‡æˆäº¤é‡çš„æ¯”å€¼
VOLUME_DAYS = 4
# æˆäº¤é‡æ¯”é˜ˆå€¼ï¼Œè¶…è¿‡è¯¥å€¼åˆ™åœ¨å•å…ƒæ ¼ä¸­æ˜¾ç¤ºæˆäº¤é‡æ¯”
VOLUME_RATIO_THRESHOLD = 2.2
# æˆäº¤é‡æ¯”ä½é˜ˆå€¼ï¼Œä½äºè¯¥å€¼åˆ™åœ¨å•å…ƒæ ¼ä¸­æ˜¾ç¤ºæˆäº¤é‡æ¯”
VOLUME_RATIO_LOW_THRESHOLD = 0.4

# ==================== æ–°é«˜åˆ†æç›¸å…³å‚æ•° ====================
# è®¡ç®—æ–°é«˜çš„å¤©æ•°ï¼Œå½“å¤©æ”¶ç›˜ä»·ä¸å‰Xå¤©æœ€é«˜ä»·çš„æ¯”è¾ƒ
NEW_HIGH_DAYS = 200
# æ–°é«˜æ ‡è®°ç¬¦å·
NEW_HIGH_MARKER = '!!'

# ==================== å‡çº¿æ–œç‡åˆ†æç›¸å…³å‚æ•° ====================
# è®¡ç®—å‡çº¿æ–œç‡çš„å¤©æ•°
MA_SLOPE_DAYS = 5
# å‡çº¿æ–œç‡æ˜¾ç¤ºé˜ˆå€¼ï¼Œåªæœ‰ç›¸å¯¹å˜åŒ–è¶…è¿‡æ­¤é˜ˆå€¼æ‰æ˜¾ç¤ºè¶‹åŠ¿æ ‡è®°
MA_SLOPE_THRESHOLD_PCT = 2  # å•ä½ï¼š%ï¼Œå‡çº¿æ—¥å˜åŒ–ç‡é˜ˆå€¼

# ==================== é«˜æ¶¨å¹…è·Ÿè¸ªç›¸å…³å‚æ•° ====================
# æŒç»­è·Ÿè¸ªçš„æ¶¨å¹…é˜ˆå€¼ï¼Œå¦‚æœè‚¡ç¥¨åœ¨PERIOD_DAYS_CHANGEå¤©å†…æ¶¨å¹…è¶…è¿‡æ­¤å€¼ï¼Œå³ä¾¿æ²¡æœ‰æ¶¨åœä¹Ÿä¼šç»§ç»­è·Ÿè¸ª
HIGH_GAIN_TRACKING_THRESHOLD = 15.0

# ==================== æ—¥å†…æ¶¨è·Œå¹…æ ‡è®°ç›¸å…³å‚æ•° ====================
# æ—¥å†…æ¶¨å¹…é˜ˆå€¼ï¼Œè¶…è¿‡æ­¤å€¼å­—ä½“æ ‡æ·±çº¢è‰²
INTRADAY_GAIN_THRESHOLD = 7.0
# æ—¥å†…è·Œå¹…é˜ˆå€¼ï¼Œä½äºæ­¤å€¼å­—ä½“æ ‡æ·±æ©„æ¦„è‰²ï¼ˆè´Ÿæ•°ï¼‰
INTRADAY_DROP_THRESHOLD = -7.0

# ==================== æŠ˜å ç›¸å…³å‚æ•° ====================
# æ–­æ¿åæŠ˜å è¡Œçš„å¤©æ•°é˜ˆå€¼ï¼Œè¶…è¿‡è¿™ä¸ªå¤©æ•°çš„è‚¡ç¥¨ä¼šåœ¨Excelä¸­è‡ªåŠ¨æŠ˜å ï¼ˆéšè—ï¼‰
# è®¾ç½®ä¸ºNoneè¡¨ç¤ºä¸è‡ªåŠ¨æŠ˜å ä»»ä½•è¡Œ
COLLAPSE_DAYS_AFTER_BREAK = 12

# ==================== ç¼“å­˜å˜é‡ ====================
# é«˜æ¶¨å¹…è®¡ç®—ç¼“å­˜ï¼Œé¿å…é‡å¤è®¡ç®—
_high_gain_cache = {}

# æ–°é«˜æ ‡è®°ç¼“å­˜ï¼Œé¿å…é‡å¤è®¡ç®—
_new_high_markers_cache = None

# å‡çº¿æ–œç‡ç¼“å­˜
_ma_slope_cache = {}

# æ–œç‡ç»Ÿè®¡ä¿¡æ¯ï¼ˆç”¨äºåˆ†æå’Œè°ƒè¯•ï¼‰
_slope_stats = {'min': float('inf'), 'max': float('-inf'), 'count': 0, 'sum': 0}

# ç‚¸æ¿æ ¼å¼ç¼“å­˜ï¼Œç”¨äºåœ¨Aå’ŒB sheetä¹‹é—´å…±äº«ç‚¸æ¿æ ¼å¼ä¿¡æ¯
_zaban_format_cache = {}


# ==================== ç¼“å­˜ç®¡ç†å‡½æ•° ====================

def clear_helper_caches():
    """æ¸…ç†æœ¬æ¨¡å—çš„æ‰€æœ‰ç¼“å­˜"""
    global _high_gain_cache, _new_high_markers_cache, _ma_slope_cache, _slope_stats, _zaban_format_cache
    _high_gain_cache.clear()
    _new_high_markers_cache = None
    _ma_slope_cache.clear()
    _slope_stats = {'min': float('inf'), 'max': float('-inf'), 'count': 0, 'sum': 0}
    _zaban_format_cache.clear()


def cache_zaban_format(stock_code, formatted_day, is_zaban):
    """
    ç¼“å­˜ç‚¸æ¿æ ¼å¼ä¿¡æ¯

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        formatted_day: æ ¼å¼åŒ–çš„æ—¥æœŸ
        is_zaban: æ˜¯å¦ä¸ºç‚¸æ¿
    """
    global _zaban_format_cache
    key = f"{stock_code}_{formatted_day}"
    _zaban_format_cache[key] = is_zaban


def get_cached_zaban_format(stock_code, formatted_day):
    """
    è·å–ç¼“å­˜çš„ç‚¸æ¿æ ¼å¼ä¿¡æ¯

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        formatted_day: æ ¼å¼åŒ–çš„æ—¥æœŸ

    Returns:
        bool: æ˜¯å¦ä¸ºç‚¸æ¿ï¼Œå¦‚æœç¼“å­˜ä¸­æ²¡æœ‰åˆ™è¿”å›None
    """
    global _zaban_format_cache
    key = f"{stock_code}_{formatted_day}"
    return _zaban_format_cache.get(key)


# ==================== è‚¡ç¥¨æ•°æ®è·å–å‡½æ•° ====================

@lru_cache(maxsize=1000)
def get_stock_data_df(stock_code):
    """ç¼“å­˜è‚¡ç¥¨æ–‡ä»¶è¯»å–ç»“æœ"""
    return read_stock_data(stock_code)


@lru_cache(maxsize=1000)
def get_stock_data(stock_code, date_str_yyyymmdd):
    """
    è·å–æŒ‡å®šè‚¡ç¥¨åœ¨ç‰¹å®šæ—¥æœŸçš„æ•°æ®ï¼Œä½¿ç”¨ç¼“å­˜é¿å…é‡å¤è¯»å–æ–‡ä»¶

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        date_str_yyyymmdd: ç›®æ ‡æ—¥æœŸ (YYYYMMDD)

    Returns:
        tuple: (DataFrame, ç›®æ ‡è¡Œ, ç›®æ ‡ç´¢å¼•) å¦‚æœæ•°æ®ä¸å­˜åœ¨åˆ™è¿”å›(None, None, None)
    """
    try:
        if not stock_code:
            return None, None, None

        # ç›®æ ‡æ—¥æœŸï¼ˆYYYY-MM-DDæ ¼å¼ï¼‰
        target_date = f"{date_str_yyyymmdd[:4]}-{date_str_yyyymmdd[4:6]}-{date_str_yyyymmdd[6:8]}"

        df = get_stock_data_df(stock_code)

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°æ–‡ä»¶
        if df is None:
            return None, None, None

        # æŸ¥æ‰¾ç›®æ ‡æ—¥æœŸçš„æ•°æ®
        target_row = df[df['æ—¥æœŸ'] == target_date]

        # å¦‚æœæ‰¾åˆ°æ•°æ®
        if not target_row.empty:
            # è·å–ç›®æ ‡æ—¥æœŸçš„ç´¢å¼•
            target_idx = df[df['æ—¥æœŸ'] == target_date].index[0]
            return df, target_row, target_idx

        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å¯¹åº”æ—¥æœŸçš„æ•°æ®
        return df, None, None

    except Exception as e:
        print(f"è·å–è‚¡ç¥¨ {stock_code} åœ¨ {date_str_yyyymmdd} çš„æ•°æ®æ—¶å‡ºé”™: {e}")
        return None, None, None


def get_stock_daily_pct_change(stock_code, date_str_yyyymmdd):
    """
    è·å–æŒ‡å®šè‚¡ç¥¨åœ¨ç‰¹å®šæ—¥æœŸçš„æ¶¨è·Œå¹…

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        date_str_yyyymmdd: ç›®æ ‡æ—¥æœŸ (YYYYMMDD)

    Returns:
        float: æ¶¨è·Œå¹…ç™¾åˆ†æ¯”ï¼Œå¦‚æœæ•°æ®ä¸å­˜åœ¨åˆ™è¿”å›None
    """
    _, target_row, _ = get_stock_data(stock_code, date_str_yyyymmdd)

    if target_row is not None and not target_row.empty:
        return target_row['æ¶¨è·Œå¹…'].values[0]

    return None


def get_intraday_pct_change(stock_code, date_str_yyyymmdd):
    """
    è·å–æŒ‡å®šè‚¡ç¥¨åœ¨ç‰¹å®šæ—¥æœŸçš„æ—¥å†…æ¶¨è·Œå¹…
    æ—¥å†…æ¶¨è·Œå¹… = (æ”¶ç›˜ä»· - å¼€ç›˜ä»·) / å¼€ç›˜ä»· Ã— 100%

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        date_str_yyyymmdd: ç›®æ ‡æ—¥æœŸ (YYYYMMDD)

    Returns:
        float: æ—¥å†…æ¶¨è·Œå¹…ç™¾åˆ†æ¯”ï¼Œå¦‚æœæ•°æ®ä¸å­˜åœ¨åˆ™è¿”å›None
    """
    _, target_row, _ = get_stock_data(stock_code, date_str_yyyymmdd)

    if target_row is not None and not target_row.empty:
        try:
            open_price = target_row['å¼€ç›˜'].values[0]
            close_price = target_row['æ”¶ç›˜'].values[0]
            if open_price > 0:
                return (close_price - open_price) / open_price * 100
        except (KeyError, IndexError):
            pass

    return None


# ==================== æˆäº¤é‡æ¯”ç›¸å…³å‡½æ•° ====================

def get_volume_ratio(stock_code, date_str_yyyymmdd):
    """
    è·å–æŒ‡å®šè‚¡ç¥¨åœ¨ç‰¹å®šæ—¥æœŸçš„æˆäº¤é‡æ¯”(å½“å¤©æˆäº¤é‡/å‰Nå¤©å¹³å‡æˆäº¤é‡)

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        date_str_yyyymmdd: ç›®æ ‡æ—¥æœŸ (YYYYMMDD)

    Returns:
        tuple: (æˆäº¤é‡æ¯”, æ˜¯å¦è¶…è¿‡é«˜é˜ˆå€¼, æ˜¯å¦ä½äºä½é˜ˆå€¼) å¦‚æœæ•°æ®ä¸å­˜åœ¨åˆ™è¿”å›(None, False, False)
    """
    df, target_row, target_idx = get_stock_data(stock_code, date_str_yyyymmdd)

    if df is None or target_row is None or target_row.empty:
        return None, False, False

    try:
        # è·å–å½“å¤©æˆäº¤é‡
        current_volume = target_row['æˆäº¤é‡'].values[0]

        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®æ¥è®¡ç®—å¹³å‡æˆäº¤é‡
        if target_idx >= VOLUME_DAYS:
            # è·å–å‰VOLUME_DAYSå¤©çš„æ•°æ®
            prev_volumes = df.iloc[target_idx - VOLUME_DAYS:target_idx]['æˆäº¤é‡'].values

            # è®¡ç®—å¹³å‡æˆäº¤é‡
            avg_volume = prev_volumes.mean()

            # è®¡ç®—æˆäº¤é‡æ¯”
            if avg_volume > 0:
                volume_ratio = current_volume / avg_volume

                # åˆ¤æ–­æ˜¯å¦è¶…è¿‡é«˜é˜ˆå€¼æˆ–ä½äºä½é˜ˆå€¼
                is_high_volume = volume_ratio >= VOLUME_RATIO_THRESHOLD
                is_low_volume = volume_ratio <= VOLUME_RATIO_LOW_THRESHOLD

                return volume_ratio, is_high_volume, is_low_volume

    except Exception as e:
        print(f"è®¡ç®—è‚¡ç¥¨ {stock_code} åœ¨ {date_str_yyyymmdd} çš„æˆäº¤é‡æ¯”æ—¶å‡ºé”™: {e}")

    return None, False, False


def add_volume_ratio_to_text(text, stock_code, date_str_yyyymmdd):
    """
    æ ¹æ®æˆäº¤é‡æ¯”å‘æ–‡æœ¬æ·»åŠ æˆäº¤é‡ä¿¡æ¯

    Args:
        text: åŸå§‹æ–‡æœ¬
        stock_code: è‚¡ç¥¨ä»£ç 
        date_str_yyyymmdd: æ—¥æœŸå­—ç¬¦ä¸²(YYYYMMDDæ ¼å¼)

    Returns:
        str: æ·»åŠ æˆäº¤é‡ä¿¡æ¯åçš„æ–‡æœ¬
    """
    volume_ratio, is_high_volume, is_low_volume = get_volume_ratio(stock_code, date_str_yyyymmdd)

    if volume_ratio is not None and (is_high_volume or is_low_volume):
        return f"{text}[{volume_ratio:.1f}]"

    return text


# ==================== æ–°é«˜æ ‡è®°ç›¸å…³å‡½æ•° ====================

def is_new_high(stock_code, date_str_yyyymmdd, days=NEW_HIGH_DAYS):
    """
    æ£€æŸ¥æŒ‡å®šè‚¡ç¥¨åœ¨ç‰¹å®šæ—¥æœŸæ˜¯å¦çªç ´æ–°é«˜

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        date_str_yyyymmdd: æ—¥æœŸå­—ç¬¦ä¸²(YYYYMMDDæ ¼å¼)
        days: æ£€æŸ¥æ–°é«˜çš„å¤©æ•°ï¼Œé»˜è®¤ä¸ºNEW_HIGH_DAYS

    Returns:
        bool: æ˜¯å¦çªç ´æ–°é«˜
    """
    try:
        # è¯»å–è‚¡ç¥¨æ•°æ®
        stock_data = get_stock_data_df(stock_code)
        if stock_data is None or stock_data.empty:
            return False

        # å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºdatetimeæ ¼å¼ï¼Œç„¶åè½¬ä¸ºå­—ç¬¦ä¸²æ ¼å¼åŒ¹é…æ•°æ®
        target_date_str = f"{date_str_yyyymmdd[:4]}-{date_str_yyyymmdd[4:6]}-{date_str_yyyymmdd[6:8]}"

        # æ‰¾åˆ°ç›®æ ‡æ—¥æœŸçš„æ•°æ®
        target_row = stock_data[stock_data['æ—¥æœŸ'] == target_date_str]
        if target_row.empty:
            return False

        target_idx = target_row.index[0]
        current_close = target_row['æ”¶ç›˜'].values[0]

        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
        if target_idx < days:
            # å¦‚æœå†å²æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„å†å²æ•°æ®
            historical_data = stock_data.iloc[:target_idx]
        else:
            # è·å–å‰dayså¤©çš„æ•°æ®
            historical_data = stock_data.iloc[target_idx - days:target_idx]

        if historical_data.empty:
            return False

        # è·å–å†å²æœ€é«˜ä»·
        historical_high = historical_data['æœ€é«˜'].max()

        # åˆ¤æ–­æ˜¯å¦çªç ´æ–°é«˜ï¼ˆå½“å‰æ”¶ç›˜ä»·å¤§äºå†å²æœ€é«˜ä»·ï¼‰
        return current_close > historical_high

    except Exception as e:
        print(f"æ£€æŸ¥è‚¡ç¥¨ {stock_code} åœ¨ {date_str_yyyymmdd} æ˜¯å¦çªç ´æ–°é«˜æ—¶å‡ºé”™: {e}")
        return False


def is_new_high_cached(stock_data, date_str_yyyymmdd, days=NEW_HIGH_DAYS):
    """
    ä½¿ç”¨ç¼“å­˜çš„è‚¡ç¥¨æ•°æ®æ£€æŸ¥æ˜¯å¦çªç ´æ–°é«˜ï¼ˆæ€§èƒ½ä¼˜åŒ–ç‰ˆï¼‰

    Args:
        stock_data: å·²ç¼“å­˜çš„è‚¡ç¥¨æ•°æ®DataFrame
        date_str_yyyymmdd: æ—¥æœŸå­—ç¬¦ä¸²(YYYYMMDDæ ¼å¼)
        days: æ£€æŸ¥æ–°é«˜çš„å¤©æ•°ï¼Œé»˜è®¤ä¸ºNEW_HIGH_DAYS

    Returns:
        bool: æ˜¯å¦çªç ´æ–°é«˜
    """
    try:
        if stock_data is None or stock_data.empty:
            return False

        # å°†æ—¥æœŸå­—ç¬¦ä¸²è½¬æ¢ä¸ºåŒ¹é…æ ¼å¼
        target_date_str = f"{date_str_yyyymmdd[:4]}-{date_str_yyyymmdd[4:6]}-{date_str_yyyymmdd[6:8]}"

        # æ‰¾åˆ°ç›®æ ‡æ—¥æœŸçš„æ•°æ®
        target_row = stock_data[stock_data['æ—¥æœŸ'] == target_date_str]
        if target_row.empty:
            return False

        target_idx = target_row.index[0]
        current_close = target_row['æ”¶ç›˜'].values[0]

        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„å†å²æ•°æ®
        if target_idx < days:
            # å¦‚æœå†å²æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨æ‰€æœ‰å¯ç”¨çš„å†å²æ•°æ®
            historical_data = stock_data.iloc[:target_idx]
        else:
            # è·å–å‰dayså¤©çš„æ•°æ®
            historical_data = stock_data.iloc[target_idx - days:target_idx]

        if historical_data.empty:
            return False

        # è·å–å†å²æœ€é«˜ä»·
        historical_high = historical_data['æœ€é«˜'].max()

        # åˆ¤æ–­æ˜¯å¦çªç ´æ–°é«˜ï¼ˆå½“å‰æ”¶ç›˜ä»·å¤§äºå†å²æœ€é«˜ä»·ï¼‰
        return current_close > historical_high

    except Exception:
        # é™é»˜å¤„ç†é”™è¯¯ï¼Œé¿å…å¤§é‡é”™è¯¯è¾“å‡ºå½±å“æ€§èƒ½
        return False


def calculate_new_high_markers(result_df, formatted_trading_days, date_mapping):
    """
    è®¡ç®—æ¯åªè‚¡ç¥¨çš„æ–°é«˜æ ‡è®°æ—¥æœŸï¼ˆä¼˜åŒ–ç‰ˆï¼‰

    Args:
        result_df: æ˜¾è‘—è¿æ¿è‚¡ç¥¨DataFrame
        formatted_trading_days: æ ¼å¼åŒ–çš„äº¤æ˜“æ—¥åˆ—è¡¨
        date_mapping: æ—¥æœŸæ˜ å°„

    Returns:
        dict: è‚¡ç¥¨ä»£ç åˆ°æ–°é«˜æ ‡è®°æ—¥æœŸçš„æ˜ å°„ {stock_code: formatted_date}
    """
    new_high_markers = {}
    stock_data_cache = {}  # ç¼“å­˜è‚¡ç¥¨æ•°æ®ï¼Œé¿å…é‡å¤è¯»å–

    print(f"å¼€å§‹è®¡ç®—{len(result_df)}åªè‚¡ç¥¨çš„æ–°é«˜æ ‡è®°...")

    for idx, (_, stock) in enumerate(result_df.iterrows()):
        if idx % 50 == 0:  # æ¯50åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡è¿›åº¦
            print(f"æ–°é«˜æ ‡è®°è®¡ç®—è¿›åº¦: {idx}/{len(result_df)}")

        stock_code = stock['stock_code']
        pure_stock_code = stock_code.split('_')[0] if '_' in stock_code else stock_code
        if pure_stock_code.startswith(('sh', 'sz', 'bj')):
            pure_stock_code = pure_stock_code[2:]

        # ç¼“å­˜è‚¡ç¥¨æ•°æ®
        if pure_stock_code not in stock_data_cache:
            stock_data_cache[pure_stock_code] = get_stock_data_df(pure_stock_code)

        stock_data = stock_data_cache[pure_stock_code]
        if stock_data is None or stock_data.empty:
            continue

        latest_new_high_date = None

        # åªæ£€æŸ¥è·Ÿè¸ªæœŸå†…çš„äº¤æ˜“æ—¥ï¼Œé¿å…éè·Ÿè¸ªæ—¥å‡ºç°æ ‡è®°
        for formatted_day in formatted_trading_days:
            date_yyyymmdd = date_mapping.get(formatted_day)
            if date_yyyymmdd and is_new_high_cached(stock_data, date_yyyymmdd):
                latest_new_high_date = formatted_day

        if latest_new_high_date:
            new_high_markers[stock_code] = latest_new_high_date

    print(f"æ–°é«˜æ ‡è®°è®¡ç®—å®Œæˆï¼Œå…±æ‰¾åˆ°{len(new_high_markers)}åªè‚¡ç¥¨æœ‰æ–°é«˜æ ‡è®°")
    return new_high_markers


def calculate_new_high_markers_fast(result_df, formatted_trading_days, date_mapping):
    """
    å¿«é€Ÿè®¡ç®—æ–°é«˜æ ‡è®°ï¼ˆè¿›ä¸€æ­¥ä¼˜åŒ–ç‰ˆï¼‰

    Args:
        result_df: æ˜¾è‘—è¿æ¿è‚¡ç¥¨DataFrame
        formatted_trading_days: æ ¼å¼åŒ–çš„äº¤æ˜“æ—¥åˆ—è¡¨
        date_mapping: æ—¥æœŸæ˜ å°„

    Returns:
        dict: è‚¡ç¥¨ä»£ç åˆ°æ–°é«˜æ ‡è®°æ—¥æœŸçš„æ˜ å°„ {stock_code: formatted_date}
    """
    new_high_markers = {}

    # é¢„å¤„ç†ï¼šæå–æ‰€æœ‰éœ€è¦çš„è‚¡ç¥¨ä»£ç 
    stock_codes = set()
    stock_code_mapping = {}  # å®Œæ•´ä»£ç åˆ°çº¯ä»£ç çš„æ˜ å°„

    for _, stock in result_df.iterrows():
        stock_code = stock['stock_code']
        pure_stock_code = stock_code.split('_')[0] if '_' in stock_code else stock_code
        if pure_stock_code.startswith(('sh', 'sz', 'bj')):
            pure_stock_code = pure_stock_code[2:]

        stock_codes.add(pure_stock_code)
        stock_code_mapping[stock_code] = pure_stock_code

    print(f"å¼€å§‹æ‰¹é‡åŠ è½½{len(stock_codes)}åªè‚¡ç¥¨çš„æ•°æ®...")

    # æ‰¹é‡åŠ è½½è‚¡ç¥¨æ•°æ®
    stock_data_cache = {}
    loaded_count = 0
    for pure_code in stock_codes:
        stock_data_cache[pure_code] = get_stock_data_df(pure_code)
        loaded_count += 1
        if loaded_count % 100 == 0:
            print(f"æ•°æ®åŠ è½½è¿›åº¦: {loaded_count}/{len(stock_codes)}")

    print(f"å¼€å§‹è®¡ç®—{len(result_df)}åªè‚¡ç¥¨çš„æ–°é«˜æ ‡è®°...")

    # æ‰¹é‡è®¡ç®—æ–°é«˜æ ‡è®°
    for idx, (_, stock) in enumerate(result_df.iterrows()):
        if idx % 100 == 0:  # æ¯100åªè‚¡ç¥¨æ‰“å°ä¸€æ¬¡è¿›åº¦
            print(f"æ–°é«˜æ ‡è®°è®¡ç®—è¿›åº¦: {idx}/{len(result_df)}")

        stock_code = stock['stock_code']
        pure_stock_code = stock_code_mapping[stock_code]

        stock_data = stock_data_cache.get(pure_stock_code)
        if stock_data is None or stock_data.empty:
            continue

        latest_new_high_date = None

        # åªæ£€æŸ¥è·Ÿè¸ªæœŸå†…çš„äº¤æ˜“æ—¥
        for formatted_day in formatted_trading_days:
            date_yyyymmdd = date_mapping.get(formatted_day)
            if date_yyyymmdd and is_new_high_cached(stock_data, date_yyyymmdd):
                latest_new_high_date = formatted_day

        if latest_new_high_date:
            new_high_markers[stock_code] = latest_new_high_date

    print(f"æ–°é«˜æ ‡è®°è®¡ç®—å®Œæˆï¼Œå…±æ‰¾åˆ°{len(new_high_markers)}åªè‚¡ç¥¨æœ‰æ–°é«˜æ ‡è®°")
    return new_high_markers


def get_new_high_markers_cached(result_df, formatted_trading_days, date_mapping):
    """
    è·å–ç¼“å­˜çš„æ–°é«˜æ ‡è®°ï¼Œå¦‚æœæ²¡æœ‰ç¼“å­˜åˆ™è®¡ç®—

    Args:
        result_df: æ˜¾è‘—è¿æ¿è‚¡ç¥¨DataFrame
        formatted_trading_days: æ ¼å¼åŒ–çš„äº¤æ˜“æ—¥åˆ—è¡¨
        date_mapping: æ—¥æœŸæ˜ å°„

    Returns:
        dict: è‚¡ç¥¨ä»£ç åˆ°æ–°é«˜æ ‡è®°æ—¥æœŸçš„æ˜ å°„
    """
    global _new_high_markers_cache

    if _new_high_markers_cache is None:
        _new_high_markers_cache = calculate_new_high_markers_fast(result_df, formatted_trading_days, date_mapping)

    return _new_high_markers_cache


# ==================== å‡çº¿æ–œç‡ç›¸å…³å‡½æ•° ====================

def calculate_ma_slope(stock_code, end_date_yyyymmdd, ma_days=MA_SLOPE_DAYS):
    """
    è®¡ç®—è‚¡ç¥¨Næ—¥å‡çº¿çš„æ–œç‡ï¼ˆç™¾åˆ†æ¯”å˜åŒ–ç‡ï¼‰

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        end_date_yyyymmdd: ç»“æŸæ—¥æœŸ (YYYYMMDDæ ¼å¼)
        ma_days: å‡çº¿å¤©æ•°ï¼Œé»˜è®¤ä¸ºMA_SLOPE_DAYS

    Returns:
        float: å‡çº¿æ—¥å˜åŒ–ç‡ï¼ˆ%ï¼‰ï¼Œæ­£æ•°è¡¨ç¤ºä¸Šå‡ï¼Œè´Ÿæ•°è¡¨ç¤ºä¸‹é™ï¼ŒNoneè¡¨ç¤ºæ•°æ®ä¸è¶³
    """
    global _ma_slope_cache, _slope_stats

    try:
        # åˆ›å»ºç¼“å­˜é”®
        cache_key = f"{stock_code}_{end_date_yyyymmdd}_{ma_days}"

        # æ£€æŸ¥ç¼“å­˜
        if cache_key in _ma_slope_cache:
            return _ma_slope_cache[cache_key]

        # è·å–è‚¡ç¥¨æ•°æ®
        df = get_stock_data_df(stock_code)
        if df is None or df.empty:
            _ma_slope_cache[cache_key] = None
            return None

        # è½¬æ¢ç»“æŸæ—¥æœŸæ ¼å¼
        end_date_str = f"{end_date_yyyymmdd[:4]}-{end_date_yyyymmdd[4:6]}-{end_date_yyyymmdd[6:8]}"

        # æ‰¾åˆ°ç»“æŸæ—¥æœŸçš„ä½ç½®
        end_row = df[df['æ—¥æœŸ'] == end_date_str]
        if end_row.empty:
            # å¦‚æœæ‰¾ä¸åˆ°ç¡®åˆ‡æ—¥æœŸï¼Œæ‰¾æœ€æ¥è¿‘çš„æ—¥æœŸ
            all_dates = pd.to_datetime(df['æ—¥æœŸ'])
            end_date_dt = pd.to_datetime(end_date_str)
            valid_dates = all_dates[all_dates <= end_date_dt]
            if valid_dates.empty:
                _ma_slope_cache[cache_key] = None
                return None
            closest_date = valid_dates.max()
            end_idx = df[df['æ—¥æœŸ'] == closest_date.strftime('%Y-%m-%d')].index[0]
        else:
            end_idx = end_row.index[0]

        # ç¡®ä¿æœ‰è¶³å¤Ÿçš„æ•°æ®è®¡ç®—å‡çº¿å’Œæ–œç‡
        # éœ€è¦è‡³å°‘ma_days + 2å¤©çš„æ•°æ®æ¥è®¡ç®—æ–œç‡ï¼ˆè‡³å°‘éœ€è¦2ä¸ªå‡çº¿ç‚¹ï¼‰
        min_required_days = ma_days + 2
        if end_idx < min_required_days - 1:
            _ma_slope_cache[cache_key] = None
            return None

        # è·å–ç”¨äºè®¡ç®—çš„æ•°æ®æ®µ
        data_segment = df.iloc[end_idx - min_required_days + 1:end_idx + 1]

        # è®¡ç®—å‡çº¿
        data_segment = data_segment.copy()
        data_segment['ma'] = data_segment['æ”¶ç›˜'].rolling(window=ma_days).mean()

        # è·å–æœ‰æ•ˆçš„å‡çº¿æ•°æ®ï¼ˆå»é™¤NaNï¼‰
        ma_data = data_segment['ma'].dropna()
        if len(ma_data) < 2:
            _ma_slope_cache[cache_key] = None
            return None

        # è®¡ç®—æ–œç‡ï¼šä½¿ç”¨æœ€åä¸¤ä¸ªå‡çº¿å€¼çš„ç›¸å¯¹å˜åŒ–ç‡
        current_ma = ma_data.iloc[-1]
        previous_ma = ma_data.iloc[-2]

        # æ–œç‡ = (æœ€æ–°å‡çº¿å€¼ - å‰ä¸€ä¸ªå‡çº¿å€¼) / å‰ä¸€ä¸ªå‡çº¿å€¼ * 100ï¼Œè½¬æ¢ä¸ºç™¾åˆ†æ¯”
        if previous_ma != 0:
            slope_pct = ((current_ma - previous_ma) / previous_ma) * 100
        else:
            slope_pct = 0.0  # é¿å…é™¤é›¶é”™è¯¯

        # æ›´æ–°æ–œç‡ç»Ÿè®¡ä¿¡æ¯
        _slope_stats['min'] = min(_slope_stats['min'], slope_pct)
        _slope_stats['max'] = max(_slope_stats['max'], slope_pct)
        _slope_stats['count'] += 1
        _slope_stats['sum'] += slope_pct

        # ç¼“å­˜ç»“æœ
        _ma_slope_cache[cache_key] = slope_pct
        return slope_pct

    except Exception as e:
        print(f"è®¡ç®—è‚¡ç¥¨ {stock_code} åœ¨ {end_date_yyyymmdd} çš„å‡çº¿æ–œç‡æ—¶å‡ºé”™: {e}")
        _ma_slope_cache[cache_key] = None
        return None


def get_ma_slope_indicator(stock_code, end_date_yyyymmdd, ma_days=MA_SLOPE_DAYS):
    """
    è·å–å‡çº¿æ–œç‡æŒ‡ç¤ºç¬¦

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        end_date_yyyymmdd: ç»“æŸæ—¥æœŸ (YYYYMMDDæ ¼å¼)
        ma_days: å‡çº¿å¤©æ•°ï¼Œé»˜è®¤ä¸ºMA_SLOPE_DAYS

    Returns:
        str: 'â†‘' è¡¨ç¤ºæ˜æ˜¾ä¸Šå‡è¶‹åŠ¿ï¼Œ'â†“' è¡¨ç¤ºæ˜æ˜¾ä¸‹é™è¶‹åŠ¿ï¼Œ'' è¡¨ç¤ºæ•°æ®ä¸è¶³æˆ–è¶‹åŠ¿ä¸æ˜æ˜¾
    """
    slope_pct = calculate_ma_slope(stock_code, end_date_yyyymmdd, ma_days)

    if slope_pct is None:
        return ''  # æ•°æ®ä¸è¶³æ—¶ä¸æ˜¾ç¤ºæ ‡è®°

    # åªæœ‰å½“æ–œç‡çš„ç»å¯¹å€¼è¶…è¿‡ç™¾åˆ†æ¯”é˜ˆå€¼æ—¶æ‰æ˜¾ç¤ºæ ‡è®°
    if abs(slope_pct) < MA_SLOPE_THRESHOLD_PCT:
        return ''  # è¶‹åŠ¿ä¸å¤Ÿæ˜æ˜¾ï¼Œä¸æ˜¾ç¤ºæ ‡è®°
    elif slope_pct > 0:
        return 'â†‘'  # æ˜æ˜¾ä¸Šå‡è¶‹åŠ¿
    else:
        return 'â†“'  # æ˜æ˜¾ä¸‹é™è¶‹åŠ¿


def clear_ma_slope_cache():
    """
    æ¸…ç†å‡çº¿æ–œç‡è®¡ç®—ç¼“å­˜ï¼Œé‡Šæ”¾å†…å­˜
    """
    global _ma_slope_cache
    _ma_slope_cache.clear()


def print_slope_statistics():
    """
    æ‰“å°å‡çº¿æ–œç‡çš„ç»Ÿè®¡ä¿¡æ¯ï¼Œå¸®åŠ©åˆ†æåˆé€‚çš„é˜ˆå€¼
    """
    global _slope_stats

    if _slope_stats['count'] == 0:
        print("ğŸ“Š å‡çº¿æ–œç‡ç»Ÿè®¡ï¼šæ— æ•°æ®")
        return

    avg_slope = _slope_stats['sum'] / _slope_stats['count']

    print(f"ğŸ“Š å‡çº¿æ–œç‡ç»Ÿè®¡ä¿¡æ¯ (åŸºäº{_slope_stats['count']}ä¸ªæ ·æœ¬):")
    print(f"   æœ€å°å€¼: {_slope_stats['min']:.4f}%")
    print(f"   æœ€å¤§å€¼: {_slope_stats['max']:.4f}%")
    print(f"   å¹³å‡å€¼: {avg_slope:.4f}%")
    print(f"   å½“å‰é˜ˆå€¼: Â±{MA_SLOPE_THRESHOLD_PCT:.2f}% (ç»å¯¹å€¼å°äºæ­¤å€¼ä¸æ˜¾ç¤ºæ ‡è®°)")

    # è®¡ç®—åœ¨å½“å‰é˜ˆå€¼ä¸‹ä¼šæ˜¾ç¤ºæ ‡è®°çš„æ¯”ä¾‹
    if _slope_stats['count'] > 0:
        # è¿™é‡Œåªæ˜¯ä¼°ç®—ï¼Œå®é™…éœ€è¦éå†æ‰€æœ‰è®¡ç®—è¿‡çš„æ–œç‡å€¼
        range_width = _slope_stats['max'] - _slope_stats['min']
        threshold_range = 2 * MA_SLOPE_THRESHOLD_PCT  # ä¸Šä¸‹é˜ˆå€¼èŒƒå›´
        estimated_filtered_ratio = max(0, (range_width - threshold_range) / range_width) if range_width > 0 else 0
        print(f"   é¢„ä¼°æ˜¾ç¤ºæ ‡è®°æ¯”ä¾‹: {estimated_filtered_ratio:.1%}")

    print(f"   ğŸ’¡ å»ºè®®ï¼šå¦‚æœå¸Œæœ›è¿‡æ»¤æ›´å¤šå™ªéŸ³ï¼Œå¯å¢å¤§MA_SLOPE_THRESHOLD_PCTå€¼")


# ==================== é«˜æ¶¨å¹…è·Ÿè¸ªç›¸å…³å‡½æ•° ====================

def should_track_high_gain_stock(stock_code, current_date_obj, period_days, calculate_period_change_func):
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥è·Ÿè¸ªé«˜æ¶¨å¹…è‚¡ç¥¨ï¼ˆå³ä¾¿æ²¡æœ‰æ¶¨åœï¼‰

    ä¼˜åŒ–ç­–ç•¥ï¼š
    1. ä½¿ç”¨ç¼“å­˜é¿å…é‡å¤è®¡ç®—
    2. ç¼“å­˜é”®åŒ…å«è‚¡ç¥¨ä»£ç ã€æ—¥æœŸå’Œå‘¨æœŸå¤©æ•°

    Args:
        stock_code: è‚¡ç¥¨ä»£ç 
        current_date_obj: å½“å‰æ—¥æœŸå¯¹è±¡
        period_days: è®¡ç®—æ¶¨è·Œå¹…çš„å‘¨æœŸå¤©æ•°
        calculate_period_change_func: è®¡ç®—å‘¨æœŸæ¶¨è·Œå¹…çš„å‡½æ•°

    Returns:
        bool: æ˜¯å¦åº”è¯¥è·Ÿè¸ª
    """
    global _high_gain_cache

    try:
        current_date_str = current_date_obj.strftime('%Y%m%d')

        # åˆ›å»ºç¼“å­˜é”®
        cache_key = f"{stock_code}_{current_date_str}_{period_days}"

        # æ£€æŸ¥ç¼“å­˜
        if cache_key in _high_gain_cache:
            return _high_gain_cache[cache_key]

        # è®¡ç®—å½“å‰æ—¥æœŸå‰period_daysä¸ªäº¤æ˜“æ—¥çš„å¼€å§‹æ—¥æœŸ
        start_date = get_n_trading_days_before(current_date_str, period_days)

        if '-' in start_date:
            start_date = start_date.replace('-', '')

        # è®¡ç®—æœŸé—´æ¶¨è·Œå¹…
        period_change = calculate_period_change_func(stock_code, start_date, current_date_str)

        # åˆ¤æ–­æ˜¯å¦è¶…è¿‡é˜ˆå€¼
        result = period_change is not None and period_change >= HIGH_GAIN_TRACKING_THRESHOLD

        # ç¼“å­˜ç»“æœ
        _high_gain_cache[cache_key] = result

        return result

    except Exception:
        # å¦‚æœè®¡ç®—å‡ºé”™ï¼Œç¼“å­˜Falseç»“æœï¼Œä¸å½±å“æ­£å¸¸è·Ÿè¸ªé€»è¾‘
        _high_gain_cache[cache_key] = False
        return False


def clear_high_gain_cache():
    """
    æ¸…ç†é«˜æ¶¨å¹…è®¡ç®—ç¼“å­˜ï¼Œé‡Šæ”¾å†…å­˜
    """
    global _high_gain_cache
    _high_gain_cache.clear()


def should_track_after_break(stock, current_date_obj, max_tracking_days, period_days, calculate_period_change_func):
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥è·Ÿè¸ªæ–­æ¿åçš„è‚¡ç¥¨

    ç°åœ¨ä¸ä»…è·Ÿè¸ªæ–­æ¿åçš„è¿æ¿è‚¡ï¼Œä¹Ÿè·Ÿè¸ªæŒç»­é«˜æ¶¨å¹…çš„éæ¶¨åœè‚¡ç¥¨

    Args:
        stock: è‚¡ç¥¨æ•°æ®
        current_date_obj: å½“å‰æ—¥æœŸå¯¹è±¡
        max_tracking_days: æ–­æ¿åè·Ÿè¸ªçš„æœ€å¤§å¤©æ•°
        period_days: è®¡ç®—æ¶¨è·Œå¹…çš„å‘¨æœŸå¤©æ•°
        calculate_period_change_func: è®¡ç®—å‘¨æœŸæ¶¨è·Œå¹…çš„å‡½æ•°

    Returns:
        bool: æ˜¯å¦åº”è¯¥è·Ÿè¸ª
    """
    # å¦‚æœæ²¡æœ‰è®¾ç½®æœ€å¤§è·Ÿè¸ªå¤©æ•°ï¼Œå§‹ç»ˆè·Ÿè¸ª
    if max_tracking_days is None:
        return True

    # ä¼˜å…ˆæ£€æŸ¥ä¼ ç»Ÿçš„è¿æ¿è·Ÿè¸ªé€»è¾‘
    last_board_date = stock.get('last_board_date')
    if last_board_date:
        # è®¡ç®—å½“å‰æ—¥æœŸä¸æœ€åè¿æ¿æ—¥æœŸçš„äº¤æ˜“æ—¥å¤©æ•°å·®
        days_after_break = count_trading_days_between(last_board_date, current_date_obj)
        # å¦‚æœåœ¨è·Ÿè¸ªæœŸé™å†…ï¼Œç›´æ¥è¿”å›Trueï¼Œæ— éœ€è®¡ç®—æ¶¨è·Œå¹…
        if days_after_break <= max_tracking_days:
            return True
        # å¦‚æœè¶…è¿‡è·Ÿè¸ªæœŸé™ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºé«˜æ¶¨å¹…è‚¡ç¥¨
        elif should_track_high_gain_stock(stock['stock_code'], current_date_obj, period_days,
                                          calculate_period_change_func):
            return True
        else:
            return False

    # å¦‚æœæ²¡æœ‰è¿æ¿è®°å½•ï¼Œæ£€æŸ¥æ˜¯å¦ä¸ºé«˜æ¶¨å¹…è‚¡ç¥¨
    return should_track_high_gain_stock(stock['stock_code'], current_date_obj, period_days,
                                        calculate_period_change_func)


def should_track_before_entry(current_date_obj, entry_date, max_tracking_days_before):
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥è·Ÿè¸ªå…¥é€‰å‰çš„è‚¡ç¥¨

    Args:
        current_date_obj: å½“å‰æ—¥æœŸå¯¹è±¡
        entry_date: å…¥é€‰æ—¥æœŸå¯¹è±¡
        max_tracking_days_before: å…¥é€‰å‰è·Ÿè¸ªçš„æœ€å¤§å¤©æ•°

    Returns:
        bool: æ˜¯å¦åº”è¯¥è·Ÿè¸ª
    """
    # å¦‚æœä¸è·Ÿè¸ªå…¥é€‰å‰çš„èµ°åŠ¿
    if max_tracking_days_before <= 0:
        return False

    # è®¡ç®—å½“å‰æ—¥æœŸä¸é¦–æ¬¡æ˜¾è‘—è¿æ¿æ—¥æœŸçš„äº¤æ˜“æ—¥å¤©æ•°å·®
    days_before_entry = count_trading_days_between(current_date_obj, entry_date)

    # å¦‚æœåœ¨å…¥é€‰å‰è·Ÿè¸ªå¤©æ•°èŒƒå›´å†…ï¼Œæ˜¾ç¤ºæ¶¨è·Œå¹…
    return 1 <= days_before_entry <= max_tracking_days_before


def calculate_last_board_date(stock, formatted_trading_days):
    """
    è®¡ç®—è‚¡ç¥¨çš„æœ€åè¿æ¿æ—¥æœŸï¼ˆéå†æ‰€æœ‰äº¤æ˜“æ—¥ï¼Œæ‰¾åˆ°æœ€åä¸€æ¬¡æœ‰è¿æ¿æ•°æ®çš„æ—¥æœŸï¼‰

    Args:
        stock: è‚¡ç¥¨æ•°æ®ï¼ˆéœ€åŒ…å«all_board_dataå­—æ®µï¼‰
        formatted_trading_days: æ ¼å¼åŒ–çš„äº¤æ˜“æ—¥åˆ—è¡¨

    Returns:
        datetime: æœ€åè¿æ¿æ—¥æœŸï¼Œå¦‚æœæ²¡æœ‰è¿æ¿è®°å½•åˆ™è¿”å›None
    """
    all_board_data = stock.get('all_board_data', {})
    last_board_date = None

    for formatted_day in formatted_trading_days:
        board_days = all_board_data.get(formatted_day)
        if pd.notna(board_days) and board_days:
            # è§£ææ—¥æœŸ
            try:
                if 'å¹´' in formatted_day:
                    current_date = datetime.strptime(formatted_day, '%Yå¹´%mæœˆ%dæ—¥')
                else:
                    current_date = datetime.strptime(formatted_day, '%Y/%m/%d')
                last_board_date = current_date
            except:
                continue

    return last_board_date


def should_collapse_row(stock, formatted_trading_days, date_mapping, collapse_days=None):
    """
    åˆ¤æ–­æ˜¯å¦åº”è¯¥æŠ˜å æ­¤è¡Œï¼ˆåœ¨Excelä¸­éšè—ï¼‰

    Args:
        stock: è‚¡ç¥¨æ•°æ®
        formatted_trading_days: æ ¼å¼åŒ–çš„äº¤æ˜“æ—¥åˆ—è¡¨
        date_mapping: æ—¥æœŸæ˜ å°„
        collapse_days: æŠ˜å å¤©æ•°é˜ˆå€¼ï¼Œé»˜è®¤ä½¿ç”¨æ¨¡å—å¸¸é‡

    Returns:
        bool: æ˜¯å¦åº”è¯¥æŠ˜å æ­¤è¡Œ
    """
    # ä½¿ç”¨ä¼ å…¥çš„å‚æ•°æˆ–é»˜è®¤å¸¸é‡
    collapse_threshold = collapse_days if collapse_days is not None else COLLAPSE_DAYS_AFTER_BREAK

    # å¦‚æœæœªè®¾ç½®æŠ˜å å¤©æ•°ï¼Œä¸æŠ˜å 
    if collapse_threshold is None:
        return False

    # è·å–æœ€åä¸€æ¬¡è¿æ¿çš„æ—¥æœŸ
    last_board_date = stock.get('last_board_date')
    if not last_board_date:
        return False

    # è·å–åˆ†æå‘¨æœŸçš„ç»“æŸæ—¥æœŸ
    try:
        end_date_str = date_mapping.get(formatted_trading_days[-1])
        if not end_date_str:
            return False
        end_date = datetime.strptime(end_date_str, '%Y%m%d')
    except Exception as e:
        print(f"è§£æç»“æŸæ—¥æœŸæ—¶å‡ºé”™: {e}")
        return False

    # è®¡ç®—æ–­æ¿å¤©æ•°
    days_since_break = count_trading_days_between(last_board_date, end_date)

    # å¦‚æœæ–­æ¿å¤©æ•°è¶…è¿‡é˜ˆå€¼ï¼Œåˆ™æŠ˜å æ­¤è¡Œ
    return days_since_break > collapse_threshold


# ==================== ç‚¸æ¿æ£€æŸ¥ç›¸å…³å‡½æ•° ====================

def check_stock_in_zaban(zaban_df, pure_stock_code, formatted_day):
    """
    æ£€æŸ¥è‚¡ç¥¨åœ¨ç‚¸æ¿æ•°æ®ä¸­æ˜¯å¦æœ‰è®°å½•

    Args:
        zaban_df: ç‚¸æ¿æ•°æ®DataFrame
        pure_stock_code: çº¯è‚¡ç¥¨ä»£ç 
        formatted_day: æ ¼å¼åŒ–çš„æ—¥æœŸ

    Returns:
        bool: æ˜¯å¦åœ¨ç‚¸æ¿æ•°æ®ä¸­æœ‰è®°å½•
    """
    if zaban_df is None or zaban_df.empty:
        return False

    # å°†æ—¥æœŸæ ¼å¼è½¬æ¢ä¸ºYYYYMMDDæ ¼å¼
    try:
        if 'å¹´' in formatted_day:
            # ä¸­æ–‡æ ¼å¼: YYYYå¹´MMæœˆDDæ—¥
            date_obj = datetime.strptime(formatted_day, '%Yå¹´%mæœˆ%dæ—¥')
        else:
            # æ ‡å‡†æ ¼å¼: YYYY/MM/DD
            date_obj = datetime.strptime(formatted_day, '%Y/%m/%d')

        date_yyyymmdd = date_obj.strftime('%Y%m%d')

        # æŸ¥æ‰¾è¯¥è‚¡ç¥¨åœ¨è¯¥æ—¥æœŸæ˜¯å¦æœ‰ç‚¸æ¿è®°å½•
        zaban_records = zaban_df[
            (zaban_df['date'] == date_yyyymmdd) &
            (zaban_df['stock_code'].str.contains(pure_stock_code, na=False))
            ]

        return not zaban_records.empty

    except Exception as e:
        print(f"æ£€æŸ¥ç‚¸æ¿æ•°æ®æ—¶å‡ºé”™: {e}")
        return False


def check_stock_in_shouban(shouban_df, pure_stock_code, formatted_day):
    """
    æ£€æŸ¥è‚¡ç¥¨åœ¨é¦–æ¿æ•°æ®ä¸­æ˜¯å¦æœ‰è®°å½•

    Args:
        shouban_df: é¦–æ¿æ•°æ®DataFrame
        pure_stock_code: çº¯è‚¡ç¥¨ä»£ç 
        formatted_day: æ ¼å¼åŒ–çš„æ—¥æœŸ

    Returns:
        bool: æ˜¯å¦åœ¨é¦–æ¿æ•°æ®ä¸­æœ‰è®°å½•
    """
    if shouban_df is None or shouban_df.empty:
        return False

    # æŸ¥æ‰¾åœ¨é¦–æ¿æ•°æ®ä¸­æ˜¯å¦æœ‰è¯¥è‚¡ç¥¨åœ¨è¯¥æ—¥æœŸçš„è®°å½•
    shouban_row = shouban_df[(shouban_df['çº¯ä»£ç '] == pure_stock_code)]
    if not shouban_row.empty and formatted_day in shouban_row.columns and pd.notna(
            shouban_row[formatted_day].values[0]):
        # è¯¥è‚¡ç¥¨åœ¨è¯¥æ—¥æœŸæœ‰é¦–æ¿è®°å½•
        return True

    return False
