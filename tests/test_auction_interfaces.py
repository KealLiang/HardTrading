"""
æµ‹è¯•é›†åˆç«ä»·ç›¸å…³æ¥å£æ•°æ®

è¯¦ç»†æµ‹è¯•akshareçš„æ¶¨åœæ¿å’Œè·Œåœæ¿æ¥å£ï¼Œåˆ†ææ•°æ®ç»“æ„å’Œç‰¹ç‚¹ï¼Œ
å¸®åŠ©ç†è§£æ¥å£çš„å±€é™æ€§å’Œä½¿ç”¨æ–¹æ³•ã€‚

ä½œè€…ï¼šTrading System
åˆ›å»ºæ—¶é—´ï¼š2025-01-14
"""

import sys
import os
sys.path.append('.')

try:
    import akshare as ak
    import pandas as pd
    from datetime import datetime, timedelta
    print("âœ… æˆåŠŸå¯¼å…¥åŸºç¡€åº“")
except ImportError as e:
    print(f"âŒ å¯¼å…¥åŸºç¡€åº“å¤±è´¥: {e}")
    sys.exit(1)

try:
    from utils.date_util import get_prev_trading_day, is_trading_day
    print("âœ… æˆåŠŸå¯¼å…¥æ—¥æœŸå·¥å…·")
except ImportError as e:
    print(f"âš ï¸  å¯¼å…¥æ—¥æœŸå·¥å…·å¤±è´¥ï¼Œä½¿ç”¨ç®€åŒ–ç‰ˆæœ¬: {e}")

    def get_prev_trading_day(date_str):
        """ç®€åŒ–ç‰ˆæœ¬çš„è·å–å‰ä¸€äº¤æ˜“æ—¥"""
        from datetime import datetime, timedelta
        date = datetime.strptime(date_str, '%Y%m%d')
        # ç®€å•åœ°å‡å»1-3å¤©æ¥æ‰¾åˆ°å¯èƒ½çš„äº¤æ˜“æ—¥
        for i in range(1, 4):
            prev_date = date - timedelta(days=i)
            if prev_date.weekday() < 5:  # å‘¨ä¸€åˆ°å‘¨äº”
                return prev_date.strftime('%Y%m%d')
        return (date - timedelta(days=1)).strftime('%Y%m%d')

    def is_trading_day(date_str):
        """ç®€åŒ–ç‰ˆæœ¬çš„äº¤æ˜“æ—¥åˆ¤æ–­"""
        from datetime import datetime
        date = datetime.strptime(date_str, '%Y%m%d')
        return date.weekday() < 5  # ç®€å•åˆ¤æ–­ï¼šå‘¨ä¸€åˆ°å‘¨äº”

import json


def test_zt_pool_interface():
    """æµ‹è¯•æ¶¨åœæ¿æ¥å£è¯¦ç»†æ•°æ®"""
    print("=" * 80)
    print("ğŸ“Š æµ‹è¯•æ¶¨åœæ¿æ¥å£ (ak.stock_zt_pool_em)")
    print("=" * 80)
    
    # è·å–æœ€è¿‘çš„äº¤æ˜“æ—¥
    today = datetime.now().strftime('%Y%m%d')
    if not is_trading_day(today):
        trading_day = get_prev_trading_day(today)
    else:
        trading_day = today
    
    print(f"æµ‹è¯•æ—¥æœŸ: {trading_day}")
    
    try:
        # è·å–æ¶¨åœæ¿æ•°æ®
        zt_data = ak.stock_zt_pool_em(date=trading_day)
        
        print(f"âœ… æˆåŠŸè·å–æ•°æ®ï¼Œå…± {len(zt_data)} åªè‚¡ç¥¨")
        print(f"ğŸ“‹ æ•°æ®åˆ—å: {list(zt_data.columns)}")
        
        # æ˜¾ç¤ºæ•°æ®ç±»å‹
        print(f"\nğŸ“Š æ•°æ®ç±»å‹:")
        for col in zt_data.columns:
            print(f"  {col}: {zt_data[col].dtype}")
        
        # æ˜¾ç¤ºå‰5è¡Œå®Œæ•´æ•°æ®
        print(f"\nğŸ“„ å‰5è¡Œå®Œæ•´æ•°æ®:")
        pd.set_option('display.max_columns', None)
        pd.set_option('display.width', None)
        print(zt_data.head())
        
        # åˆ†æé¦–æ¬¡å°æ¿æ—¶é—´
        print(f"\nâ° é¦–æ¬¡å°æ¿æ—¶é—´åˆ†æ:")
        time_analysis = zt_data['é¦–æ¬¡å°æ¿æ—¶é—´'].value_counts().head(20)
        print(time_analysis)
        
        # åˆ†æç«ä»·é˜¶æ®µæ•°æ®
        print(f"\nğŸ¯ ç«ä»·é˜¶æ®µåˆ†æ (092å¼€å¤´çš„æ—¶é—´):")
        auction_mask = zt_data['é¦–æ¬¡å°æ¿æ—¶é—´'].astype(str).str.startswith('092')
        auction_stocks = zt_data[auction_mask]
        print(f"ç«ä»·é˜¶æ®µå°æ¿è‚¡ç¥¨æ•°é‡: {len(auction_stocks)}")
        
        if not auction_stocks.empty:
            print("ç«ä»·é˜¶æ®µå°æ¿è‚¡ç¥¨è¯¦æƒ…:")
            for _, row in auction_stocks.iterrows():
                print(f"  {row['ä»£ç ']} {row['åç§°']}: å°å• {row['å°æ¿èµ„é‡‘']:,.0f} å…ƒ, æ—¶é—´ {row['é¦–æ¬¡å°æ¿æ—¶é—´']}")
        
        # åˆ†æå°å•é¢åˆ†å¸ƒ
        print(f"\nğŸ’° å°å•é¢ç»Ÿè®¡:")
        print(f"  æœ€å¤§å°å•é¢: {zt_data['å°æ¿èµ„é‡‘'].max():,.0f} å…ƒ")
        print(f"  æœ€å°å°å•é¢: {zt_data['å°æ¿èµ„é‡‘'].min():,.0f} å…ƒ")
        print(f"  å¹³å‡å°å•é¢: {zt_data['å°æ¿èµ„é‡‘'].mean():,.0f} å…ƒ")
        print(f"  å°å•é¢ä¸­ä½æ•°: {zt_data['å°æ¿èµ„é‡‘'].median():,.0f} å…ƒ")
        
        # ä¿å­˜è¯¦ç»†æ•°æ®ç”¨äºåˆ†æ
        output_file = f"temp/zt_data_sample_{trading_day}.csv"
        zt_data.to_csv(output_file, index=False, encoding='utf-8-sig')
        print(f"\nğŸ’¾ è¯¦ç»†æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
        
        return zt_data
        
    except Exception as e:
        print(f"âŒ æ¶¨åœæ¿æ¥å£æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return pd.DataFrame()


def test_dt_pool_interface():
    """æµ‹è¯•è·Œåœæ¿æ¥å£"""
    print("\n" + "=" * 80)
    print("ğŸ“‰ æµ‹è¯•è·Œåœæ¿æ¥å£")
    print("=" * 80)
    
    # è·å–æœ€è¿‘çš„äº¤æ˜“æ—¥
    today = datetime.now().strftime('%Y%m%d')
    if not is_trading_day(today):
        trading_day = get_prev_trading_day(today)
    else:
        trading_day = today
    
    print(f"æµ‹è¯•æ—¥æœŸ: {trading_day}")
    
    # å°è¯•ä¸åŒçš„è·Œåœæ¿æ¥å£
    interfaces_to_test = [
        ('stock_dt_pool_em', 'ak.stock_dt_pool_em'),
        ('stock_zt_pool_dtgc_em', 'ak.stock_zt_pool_dtgc_em'),  # å¯èƒ½çš„è·Œåœæ¥å£
    ]
    
    for interface_name, interface_desc in interfaces_to_test:
        print(f"\nğŸ” æµ‹è¯•æ¥å£: {interface_desc}")
        try:
            if hasattr(ak, interface_name):
                interface_func = getattr(ak, interface_name)
                dt_data = interface_func(date=trading_day)
                
                if dt_data is not None and not dt_data.empty:
                    print(f"âœ… æˆåŠŸè·å–æ•°æ®ï¼Œå…± {len(dt_data)} åªè‚¡ç¥¨")
                    print(f"ğŸ“‹ æ•°æ®åˆ—å: {list(dt_data.columns)}")
                    
                    # æ˜¾ç¤ºå‰5è¡Œ
                    print(f"ğŸ“„ å‰5è¡Œæ•°æ®:")
                    print(dt_data.head())
                    
                    # ä¿å­˜æ•°æ®
                    output_file = f"temp/dt_data_sample_{trading_day}_{interface_name}.csv"
                    dt_data.to_csv(output_file, index=False, encoding='utf-8-sig')
                    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {output_file}")
                    
                    return dt_data
                else:
                    print(f"âš ï¸  æ¥å£è¿”å›ç©ºæ•°æ®")
            else:
                print(f"âŒ æ¥å£ä¸å­˜åœ¨: {interface_name}")
                
        except Exception as e:
            print(f"âŒ æ¥å£ {interface_name} æµ‹è¯•å¤±è´¥: {e}")
    
    # å°è¯•å…¶ä»–å¯èƒ½çš„æ¥å£
    print(f"\nğŸ” å°è¯•æŸ¥æ‰¾å…¶ä»–è·Œåœç›¸å…³æ¥å£...")
    ak_functions = [func for func in dir(ak) if 'dt' in func.lower() or 'drop' in func.lower()]
    print(f"å¯èƒ½çš„è·Œåœç›¸å…³å‡½æ•°: {ak_functions[:10]}")  # åªæ˜¾ç¤ºå‰10ä¸ª
    
    return pd.DataFrame()


def test_realtime_vs_historical():
    """æµ‹è¯•å®æ—¶æ•°æ®ä¸å†å²æ•°æ®çš„å·®å¼‚"""
    print("\n" + "=" * 80)
    print("ğŸ• æµ‹è¯•å®æ—¶æ•°æ®ä¸å†å²æ•°æ®å·®å¼‚")
    print("=" * 80)
    
    current_time = datetime.now()
    print(f"å½“å‰æ—¶é—´: {current_time.strftime('%Y-%m-%d %H:%M:%S')}")
    
    # æµ‹è¯•ä»Šå¤©å’Œæ˜¨å¤©çš„æ•°æ®
    today = current_time.strftime('%Y%m%d')
    yesterday = (current_time - timedelta(days=1)).strftime('%Y%m%d')
    
    for test_date in [today, yesterday]:
        print(f"\nğŸ“… æµ‹è¯•æ—¥æœŸ: {test_date}")
        print(f"æ˜¯å¦ä¸ºäº¤æ˜“æ—¥: {is_trading_day(test_date)}")
        
        try:
            zt_data = ak.stock_zt_pool_em(date=test_date)
            if not zt_data.empty:
                print(f"  æ¶¨åœæ¿æ•°é‡: {len(zt_data)}")
                auction_count = len(zt_data[zt_data['é¦–æ¬¡å°æ¿æ—¶é—´'].astype(str).str.startswith('092')])
                print(f"  ç«ä»·é˜¶æ®µå°æ¿: {auction_count}")
                print(f"  å°å•æ€»é¢: {zt_data['å°æ¿èµ„é‡‘'].sum():,.0f} å…ƒ")
            else:
                print(f"  æ— æ¶¨åœæ¿æ•°æ®")
        except Exception as e:
            print(f"  è·å–æ•°æ®å¤±è´¥: {e}")


def test_data_structure_analysis():
    """è¯¦ç»†åˆ†ææ•°æ®ç»“æ„"""
    print("\n" + "=" * 80)
    print("ğŸ”¬ è¯¦ç»†æ•°æ®ç»“æ„åˆ†æ")
    print("=" * 80)
    
    trading_day = get_prev_trading_day(datetime.now().strftime('%Y%m%d'))
    
    try:
        zt_data = ak.stock_zt_pool_em(date=trading_day)
        
        if zt_data.empty:
            print("âŒ æ— æ•°æ®å¯åˆ†æ")
            return
        
        print(f"ğŸ“Š æ•°æ®ç»´åº¦: {zt_data.shape}")
        
        # åˆ†æå…³é”®å­—æ®µ
        key_fields = ['ä»£ç ', 'åç§°', 'å°æ¿èµ„é‡‘', 'é¦–æ¬¡å°æ¿æ—¶é—´', 'æœ€åå°æ¿æ—¶é—´', 'ç‚¸æ¿æ¬¡æ•°']
        
        for field in key_fields:
            if field in zt_data.columns:
                print(f"\nğŸ” å­—æ®µåˆ†æ: {field}")
                print(f"  æ•°æ®ç±»å‹: {zt_data[field].dtype}")
                print(f"  éç©ºå€¼æ•°é‡: {zt_data[field].notna().sum()}")
                print(f"  å”¯ä¸€å€¼æ•°é‡: {zt_data[field].nunique()}")
                
                if field == 'ä»£ç ':
                    # åˆ†æè‚¡ç¥¨ä»£ç æ ¼å¼
                    print(f"  ä»£ç ç¤ºä¾‹: {zt_data[field].head().tolist()}")
                    print(f"  ä»£ç é•¿åº¦åˆ†å¸ƒ: {zt_data[field].astype(str).str.len().value_counts()}")
                
                elif field == 'é¦–æ¬¡å°æ¿æ—¶é—´':
                    # åˆ†ææ—¶é—´æ ¼å¼
                    print(f"  æ—¶é—´ç¤ºä¾‹: {zt_data[field].head().tolist()}")
                    print(f"  æ—¶é—´é•¿åº¦åˆ†å¸ƒ: {zt_data[field].astype(str).str.len().value_counts()}")
                    
                    # åˆ†æç«ä»·æ—¶é—´æ®µ
                    auction_times = zt_data[zt_data[field].astype(str).str.startswith('092')][field]
                    if not auction_times.empty:
                        print(f"  ç«ä»·æ—¶é—´æ®µæ ·æœ¬: {auction_times.tolist()}")
                
                elif field == 'å°æ¿èµ„é‡‘':
                    # åˆ†æå°å•é¢åˆ†å¸ƒ
                    print(f"  æœ€å¤§å€¼: {zt_data[field].max():,.0f}")
                    print(f"  æœ€å°å€¼: {zt_data[field].min():,.0f}")
                    print(f"  åˆ†ä½æ•°:")
                    for q in [0.25, 0.5, 0.75, 0.9, 0.95]:
                        print(f"    {q*100}%: {zt_data[field].quantile(q):,.0f}")
        
        # ç”Ÿæˆæ•°æ®å­—å…¸
        data_dict = {
            'date': trading_day,
            'total_stocks': len(zt_data),
            'columns': list(zt_data.columns),
            'data_types': {col: str(zt_data[col].dtype) for col in zt_data.columns},
            'sample_data': zt_data.head(3).to_dict('records'),
            'auction_analysis': {
                'auction_stocks_count': len(zt_data[zt_data['é¦–æ¬¡å°æ¿æ—¶é—´'].astype(str).str.startswith('092')]),
                'auction_times': zt_data[zt_data['é¦–æ¬¡å°æ¿æ—¶é—´'].astype(str).str.startswith('092')]['é¦–æ¬¡å°æ¿æ—¶é—´'].tolist(),
            }
        }
        
        # ä¿å­˜æ•°æ®å­—å…¸
        dict_file = f"temp/data_structure_analysis_{trading_day}.json"
        with open(dict_file, 'w', encoding='utf-8') as f:
            json.dump(data_dict, f, ensure_ascii=False, indent=2, default=str)
        
        print(f"\nğŸ’¾ æ•°æ®ç»“æ„åˆ†æå·²ä¿å­˜åˆ°: {dict_file}")
        
    except Exception as e:
        print(f"âŒ æ•°æ®ç»“æ„åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª é›†åˆç«ä»·æ¥å£è¯¦ç»†æµ‹è¯•")
    print("=" * 80)
    print("æœ¬æµ‹è¯•å°†è¯¦ç»†åˆ†æakshareç›¸å…³æ¥å£çš„æ•°æ®ç»“æ„å’Œç‰¹ç‚¹")
    print()
    
    # ç¡®ä¿æµ‹è¯•ç›®å½•å­˜åœ¨
    os.makedirs('temp', exist_ok=True)
    
    # 1. æµ‹è¯•æ¶¨åœæ¿æ¥å£
    zt_data = test_zt_pool_interface()
    
    # 2. æµ‹è¯•è·Œåœæ¿æ¥å£
    dt_data = test_dt_pool_interface()
    
    # 3. æµ‹è¯•å®æ—¶vså†å²æ•°æ®
    test_realtime_vs_historical()
    
    # 4. è¯¦ç»†æ•°æ®ç»“æ„åˆ†æ
    test_data_structure_analysis()
    
    print("\n" + "=" * 80)
    print("ğŸ¯ æµ‹è¯•æ€»ç»“")
    print("=" * 80)
    print("âœ… æ¶¨åœæ¿æ¥å£æµ‹è¯•å®Œæˆ")
    print("âœ… è·Œåœæ¿æ¥å£æµ‹è¯•å®Œæˆ")
    print("âœ… æ•°æ®ç»“æ„åˆ†æå®Œæˆ")
    print("ğŸ“ æµ‹è¯•ç»“æœæ–‡ä»¶ä¿å­˜åœ¨ temp/ ç›®å½•ä¸‹")
    print("\nğŸ’¡ å»ºè®®:")
    print("1. æŸ¥çœ‹ç”Ÿæˆçš„CSVæ–‡ä»¶äº†è§£è¯¦ç»†æ•°æ®ç»“æ„")
    print("2. æŸ¥çœ‹JSONæ–‡ä»¶äº†è§£æ•°æ®åˆ†æç»“æœ")
    print("3. æ ¹æ®æµ‹è¯•ç»“æœè°ƒæ•´æ•°æ®é‡‡é›†ç­–ç•¥")


if __name__ == "__main__":
    main()
